# -*- coding: utf-8 -*-
"""ibmedunet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HHdezNC0MZa6SPBRKTrOp4dj465n3jCL
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

train=pd.read_csv('/content/train.csv')
test=pd.read_csv('/content/test.csv')

train.head()

train.info()

train.isnull().sum()

train.nunique()

test.isnull().sum()

train[['Gender', 'Burn Rate']].groupby('Gender').agg('mean')

train.boxplot(column=['Burn Rate'],by='Gender')

train[['WFH Setup Available', 'Burn Rate']].groupby('WFH Setup Available').agg('mean')

train.boxplot(column=['Burn Rate'], by='WFH Setup Available')

train[['Company Type', 'Burn Rate']].groupby('Company Type').agg('mean')

train.boxplot(column=['Burn Rate'], by='Company Type')

train[['Designation', 'Burn Rate']].groupby('Designation').agg('mean')

train.boxplot(column=['Burn Rate'], by='Designation')

train[['Resource Allocation', 'Burn Rate']].groupby('Resource Allocation').agg('mean')

train.boxplot(column=['Burn Rate'], by='Resource Allocation')

train[['Mental Fatigue Score', 'Burn Rate']].groupby('Mental Fatigue Score').agg('mean')

train.boxplot(column=['Burn Rate'], by='Mental Fatigue Score')

import seaborn as sns
sns.set_style(style="whitegrid")

title_font = {"family":"sans-serif",
              "weight":"bold",
              "color":"darkgreen",
              "size":16}

axis_font = {"family":"serif",
             "weight":"normal",
             "color":"darkgreen",
             "size":14}

is_male = pd.get_dummies(train.Gender, drop_first=True)
is_service = pd.get_dummies(train["Company Type"], drop_first=True)
wfh_available = pd.get_dummies(train["WFH Setup Available"], drop_first=True)

for loc, column in enumerate(["is_male", "is_service", "wfh_available"], start=2):
    train.insert(loc=loc, column=column, value=eval(column))

train.drop(columns=["Gender", "Company Type", "WFH Setup Available"], axis=1, inplace=True)

train.head()

is_male = pd.get_dummies(test.Gender, drop_first=True)
is_service = pd.get_dummies(test["Company Type"], drop_first=True)
wfh_available = pd.get_dummies(test["WFH Setup Available"], drop_first=True)

for loc, column in enumerate(["is_male", "is_service", "wfh_available"], start=2):
    test.insert(loc=loc, column=column, value=eval(column))

test.drop(columns=["Gender", "Company Type", "WFH Setup Available"],
          axis=1,
          inplace=True)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# month_dict = {"01":31, "02":29, "03":31,
#               "04":30, "05":31, "06":30,
#               "07":31, "08":31, "09":30,
#               "10":31, "11":30, "12":31}
# 
# for dataset in (train, test):
#     for i in range(len(dataset)):
#         x = dataset["Date of Joining"][i].split("-")    # sample output: ['2008', '09', '30']
#         x = eval(f"{int(x[1])} * {month_dict[x[1]]} + {int(x[2])}")    # sample output: 300
#         dataset.loc[i, "Date of Joining"] = x
#     dataset["Date of Joining"] = dataset["Date of Joining"].astype("float32")
#     dataset["Date of Joining"] = abs(dataset["Date of Joining"] - dataset["Date of Joining"].max())
#     dataset["Date of Joining"] /= dataset["Date of Joining"].max()
#

# let's dive into the details
resource_nan = train["Resource Allocation"].isna()
mental_nan = train["Mental Fatigue Score"].isna()
burnrate_nan = train["Burn Rate"].isna()

# No "Burn Rate" & "Mental Fatigue Score" values
train[(burnrate_nan) & (mental_nan)]

double_nan_indices = train[(burnrate_nan) & (mental_nan)].index

train.drop(index=double_nan_indices, axis=0, inplace=True)
train.reset_index(drop=True, inplace=True)
del double_nan_indices, is_male, is_service, wfh_available

train.isna().sum()

train_corr = train.corr()

plt.figure(figsize=(14, 6))
heatmap = sns.heatmap(train.corr(), vmin=-1, vmax=1, annot=True, center=0, cmap= 'coolwarm')
heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':14}, pad=14);
plt.savefig("heatmap.png")

plt.figure(figsize=(9, 5))
plt.scatter("Mental Fatigue Score", "Burn Rate", data=train, s=0.3, c="darkgreen")
plt.plot([0,10], [0, 1], linewidth=2, c="darkred")
plt.xlabel("Mental Fatigue Score", fontdict=axis_font)
plt.ylabel("Burn Rate", fontdict=axis_font)
plt.xticks(range(0,11))
plt.show()

LINEAR_CONST = 7 / 10

fig, (ax1, ax2) = plt.subplots(1,2, sharex=True, sharey=True, figsize=(18 ,5))
fig.suptitle("Mental Fatigue Score vs. Burn Rate", color="black", size=22)

ax1.scatter("Mental Fatigue Score",
            "Burn Rate",
            data=train,
            s=0.3,
            c="darkgreen")
ax1.plot([0,10], [0, 1], linewidth=2, c="darkred")
ax1.set_title("Original Graph")
plt.xticks(range(0,11))
ax2.scatter(train["Mental Fatigue Score"],
            train["Burn Rate"] ** LINEAR_CONST,
            s=0.3,
            c="green")
ax2.plot([0,10], [0, 1], linewidth=2, c="darkred")
ax2.set_title("Transformed Graph")

fig.text(x=0.09, y=0.5,
         s="Burn Rate",
         va="center", rotation="vertical", size=20, c="darkred")
fig.text(x=0.42, y=0.03,
         s="Mental Fatigue Score",
         va="center", rotation="horizontal", size=20, c="darkred")
plt.show()

train["Mental Fatigue Score"] **= (LINEAR_CONST**-1)
test["Mental Fatigue Score"] **= (LINEAR_CONST**-1)

train_copy = pd.DataFrame()
for i in train.columns[-3:]:
    fill_with = train[i].interpolate(method="linear")
    train_copy[i] = train[i].fillna(fill_with, inplace=False)

plt.figure(figsize=(9, 5))
plt.scatter("Mental Fatigue Score", "Burn Rate",
            data=train_copy,
            s=0.3,
            c="darkgreen")
plt.plot([0, train["Mental Fatigue Score"].max()], [0, 1],
         linewidth=2,
         c="darkred")
plt.xlabel("Mental Fatigue Score", fontdict=axis_font)
plt.ylabel("Burn Rate", fontdict=axis_font)
plt.show()

describe_original = train.describe()
describe_original

from scipy import interpolate

train_copy = train.copy(deep=True)

not_na1 = train_copy["Mental Fatigue Score"].notna()
not_na2 = train_copy["Burn Rate"].notna()

train_copy = train_copy[(not_na1) & (not_na2)]
del not_na2, not_na1

fn_burn = interpolate.interp1d(x=train_copy["Mental Fatigue Score"],
                               y=train_copy["Burn Rate"],
                               kind="linear",
                               fill_value=None)
# function to find the mental fatigue score
fn_mental = interpolate.interp1d(y=train_copy["Mental Fatigue Score"],
                                 x=train_copy["Burn Rate"],
                                 kind="linear",
                                 fill_value=None)

for i in train[train["Burn Rate"].isna()].index:
    train.loc[i, "Burn Rate"] = fn_burn(train.loc[i, "Mental Fatigue Score"])

for i in train[train["Mental Fatigue Score"].isna()].index:
    train.loc[i, "Mental Fatigue Score"] = fn_mental(train.loc[i, "Burn Rate"])

train.isna().sum()

plt.figure(figsize=(6, 5))
plt.scatter("Designation", "Resource Allocation", data=train, c="darkred")
plt.xlabel("Designation", fontdict=axis_font)
plt.ylabel("Resource Allocation", fontdict=axis_font)
plt.yticks(range(0,11))
plt.show()

temp_value = train["Resource Allocation"][train["Designation"]==1].mean()

print(f"The mean value of Resource Allocation where \
Designation == 1 is: {temp_value:.2f}")

for i in range(6):    # 0 to 5, Designation values
    mean_value = train["Resource Allocation"][train["Designation"]==i].mean()

    # condition: "Designation" == i AND "Resource Allocation" is NaN
    condition = (train["Designation"]==i) & (train["Resource Allocation"].isna())

    # all NaN values are converted to mean values:
    train.loc[condition, "Resource Allocation"] = mean_value

del temp_value, train_copy, fn_burn, fn_mental

train.isnull().sum(

)

describe_botox = train.describe()

print("--------------- Original Data ---------------")
display(describe_original.iloc[:3, -3:])
print("\n--------------- Cleaned Data ---------------")
display(describe_botox.iloc[:3, -3:])

train[['is_male', 'Burn Rate']].groupby('is_male').agg('mean')

train.boxplot(column=['Burn Rate'], by='is_male')

train.boxplot(column=['Burn Rate'], by='is_male')

train[['wfh_available', 'Burn Rate']].groupby('wfh_available').agg('mean')

train.boxplot(column=['Burn Rate'], by='wfh_available')

train[['is_service', 'Burn Rate']].groupby('is_service').agg('mean')

from sklearn.preprocessing import LabelEncoder
lr = LabelEncoder()

from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics

Id_train = train['Employee ID']
X=train.drop(['Burn Rate', 'Employee ID', 'Date of Joining'],axis=1)
train['Burn Rate']=LabelEncoder().fit_transform(train['Burn Rate'])
y=train['Burn Rate']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)
#Pred_test = df_test[df_test.columns.values.tolist()[2:7]]
X_train.shape

from sklearn.model_selection import train_test_split
#ניסיון ניצן
from sklearn.datasets import make_classification
#לא ניסיון
from sklearn.preprocessing import MinMaxScaler, StandardScaler

X_train, X_val, \
y_train, y_val = train_test_split(train.iloc[:, 1:-1],
                                         train.iloc[:, -1],
                                         test_size=0.25,
                                         shuffle=True,
                                         random_state=19)
X_test = test.iloc[:, 1:]
y_test = None

print("Shape of the train set:\nX_train:", X_train.shape)
print("y_train:", y_train.shape)
print("\nShape of the validation set:\nX_val:", X_val.shape)
print("y_val:", y_val.shape)

scale = StandardScaler()
normalize = MinMaxScaler((0, 1))

# scaled set: mean=0, standard deviation=1
X_train_std = scale.fit_transform(X_train)
X_val_std = scale.fit_transform(X_val)
X_test_std = scale.fit_transform(X_test)

# normalized set: values are between [0, 1]
X_train_norm = normalize.fit_transform(X_train)
X_val_norm = normalize.fit_transform(X_val)
X_test_norm = normalize.fit_transform(X_test)

import statsmodels.api as sm
from sklearn.metrics import mean_absolute_error as mae
from statsmodels.tools.eval_measures import mse, rmse

def show_errors(y_validations, y_predictions):
    """Function to show error statistics of the validation part.
    y_validations: Validation values
    y_predictions: Predicted values"""
    mae_fn = mae(y_validations, y_predictions)
    mse_fn = mse(y_validations, y_predictions)
    rmse_fn = rmse(y_validations, y_predictions)

    print("\n---------Error Statistics of Validation Part---------")
    print(f"Mean Absolute Error (MAE)             : {mae_fn:.4f}")
    print(f"Mean Square Error (MSE)               : {mse_fn:.4f}")
    print(f"Root Mean Square Error (RMSE)         : {rmse_fn:.4f}\n")

X_train_ols = sm.add_constant(X_train)
ols_results_model = sm.OLS(y_train, X_train_ols)
ols_results = ols_results_model.fit()

ols_results.summary()

# validation data
X_val_ols = sm.add_constant(X_val)
ols_results_val_model = sm.OLS(y_val, X_val_ols)
ols_results_val = ols_results_val_model.fit()
ols_results_val.summary()

show_errors(y_val,
            ols_results_val.predict(sm.add_constant(X_val_std))
           )

def show_comparison(y_validations, y_predictions):
    """To see the comparison, please provide:
    y_validations and y_predictions"""
    plt.figure(figsize=(12,6))
    plt.scatter(y_validations,
                y_predictions,
                color="k", alpha=0.6, s=10, label="Predicted")
    plt.plot(y_validations, y_validations, "r--", label="True")
    plt.xlabel("True Values", fontdict=axis_font)
    plt.ylabel("Predicted Values", fontdict=axis_font)
    plt.title("True vs. Predicted Values", fontdict=title_font)
    plt.legend(fontsize="large", loc="best")
    plt.show()

show_comparison(y_val,
                ols_results_val.predict(sm.add_constant(X_val_std)))

predict = ols_results.predict(X_train_ols)
errors = y_train - predict
print("The average error between the predicted & real value: \
{:.3g}".format(np.mean(errors)))

plt.figure(figsize=(12,6))
plt.scatter(predict, errors, color="darkgreen", s=3, alpha=0.75)
plt.xlabel('Predicted Value', fontdict=axis_font)
plt.ylabel('Residuals', fontdict=axis_font)
plt.axhline(y=0, color="r")
plt.title('Residuals vs. Predict', fontdict=title_font)
plt.show()

from scipy.stats import bartlett
from scipy.stats import levene

bart_stats = bartlett(predict, errors)
lev_stats = levene(predict, errors)

print("Bartlett test statistic value is {0:.2f} \
and p-value is {1:.3g}".format(bart_stats[0], bart_stats[1]))
print("Levene test statistic value is {0:.2f} \
and p-value is {1:.3g}".format(lev_stats[0], lev_stats[1]))

plt.figure(figsize=(14,4))
plt.subplot(1,2,1)
plt.plot(errors, linewidth=0.1)

plt.subplot(1,2,2)
from statsmodels.tsa.stattools import acf
acf_data = acf(errors)
plt.plot(acf_data[1:], color="red")
plt.show()

rand_nums = np.random.normal(np.mean(errors),
                             np.std(errors),
                             len(errors))
plt.figure(figsize=(14,6))
plt.subplot(1,2,1)
plt.scatter(rand_nums, errors, color="darkblue", s=3, alpha=0.75)
plt.xlabel("Normally Distributed Random Variables", fontdict=axis_font)
plt.ylabel("Errors of the Model", fontdict=axis_font)
plt.title("QQ plot", fontdict=title_font)
plt.subplot(1,2,2)
plt.hist(errors, bins=30, color="darkred")
plt.xlabel("Errors", fontdict=axis_font)
plt.title("Histogram of the Errors", fontdict=title_font)

plt.tight_layout()
plt.show()

from scipy.stats import jarque_bera
from scipy.stats import normaltest
jb_stats = jarque_bera(errors)
norm_stats = normaltest(errors)

print("Jarque-Bera test statistics is {0:.2f} and \
p value is {1:.5g}".format(jb_stats[0], jb_stats[1]))
print("Normality test statistics is {0:.2f} and p \
value is {1:5g}".format(norm_stats[0], norm_stats[1]))

from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV

lasso_CV_model = LassoCV(alphas=np.logspace(-8, 6, num=30, base=10.0),
                         cv=10,
                         n_jobs=-1)
lasso_CV = lasso_CV_model.fit(X_train_std, y_train)

lasso_CV_score = lasso_CV.score(X_train_std, y_train)
print(f"Adjusted R-square value of train set: {lasso_CV_score:.3f}")
lasso_CV_score = lasso_CV.score(X_val_std, y_val)
print(f"Adjusted R-square value of validation set: {lasso_CV_score:.3f}")

show_errors(y_val, lasso_CV.predict(X_val_std))

from keras import models, layers
from keras.optimizers import Adam, schedules

def dense_layer(unit):
    model.add(layers.Dense(units=unit))
    model.add(layers.BatchNormalization())
    model.add(layers.Activation("relu"))

model = models.Sequential()
model.add(layers.Dense(units=16,
                       input_shape=(X_train_norm.shape[1], ),
                       kernel_initializer="GlorotUniform",
                       name="Hidden_Layer1"))
model.add(layers.BatchNormalization())
model.add(layers.Activation("relu"))
#dense_layer(64)
model.add(layers.Dropout(0.05))
#dense_layer(128)
model.add(layers.Dense(1, name="Output_Layer"))
model.summary()

lr_schedule = schedules.ExponentialDecay(initial_learning_rate=1e-3,
                                         decay_steps=10000,
                                         decay_rate=0.9)

opt = Adam(learning_rate=lr_schedule)
model.compile(optimizer=opt, loss="mse", metrics=["mae"])
model_history = model.fit(X_train_norm, y_train,
                          epochs=30,
                          batch_size=32,
                          validation_data=(X_val_norm, y_val),
                          shuffle=False,
                          verbose=0)

show_errors(y_val, model.predict(X_val_norm).reshape(-1))

history_dict = model_history.history

train_loss = history_dict["loss"]
val_loss = history_dict["val_loss"]
train_mae = history_dict["mae"]
val_mae = history_dict["val_mae"]

plt.figure(figsize=(20,8))

plt.subplot(1,2,1)
plt.plot(range(1, len(train_mae)+1), train_mae,
         color="darkgreen", linewidth=2, label="Train Set")

plt.plot(range(1, len(val_mae)+1), val_mae,
        "r--", linewidth=2, label="Valdation Set")

plt.xlabel("Epochs", fontdict=axis_font)
plt.ylabel("Mean Absolute Error", fontdict=axis_font)
plt.legend(fontsize="medium", loc=(0.7,0.5))

plt.subplot(1,2,2)
plt.plot(range(1, len(train_loss)+1), train_loss,
         color="darkgreen", linewidth=2, label="Train Set")

plt.plot(range(1, len(val_loss)+1), val_loss,
        "r--", linewidth=2, label="Valdation Set")

plt.xlabel("Epochs", fontdict=axis_font)
plt.ylabel("Loss Value", fontdict=axis_font)
plt.legend(fontsize="medium", loc=(0.7,0.5))

plt.show()

